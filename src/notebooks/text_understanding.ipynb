{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8452abd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from pydantic import Field, BaseModel\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3de2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(\n",
    "    model='gemini-2.0-flash-lite',\n",
    "    temperature=0,\n",
    "    api_key = os.getenv('GEMINI_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adcb524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseSchema(BaseModel):\n",
    "    actual_input: str = Field(description=\"The actual user input\")\n",
    "    user_intent: str = Field(description=\"What the user have asked for that can be processed by LLM in next chain\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ResponseSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d121a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='''\n",
    "You are an expert in Natural Language Understanding for Inventory Management Domain.\n",
    "\n",
    "Right now you are assigned to understand what the user have asked and paraphrase it to send it to the next LLM agent.\n",
    "So you understand what the user have asked in prompt and return the same information, but in the format where agent can understand better.\n",
    "\n",
    "The user input: {text}\n",
    "\n",
    "The output should be in the following format:\n",
    "{response_schema}\n",
    "''',\n",
    "input_variables=['text'],\n",
    "partial_variables={'response_schema': parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4580487c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f61901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_input='Do we have any adhesives available for rubber tyres? If yes, where is it kept in the inventory?' user_intent='Check inventory for adhesives suitable for rubber tires and identify their storage location.'\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(input={\"text\": \"Do we have any adhesives available for rubber tyres? If yes, where is it kept in the inventory?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b32d72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_input: Do we have any adhesives available for rubber tyres? If yes, where is it kept in the inventory?\n",
      "user_intent: Check inventory for adhesives suitable for rubber tires and identify their storage location.\n"
     ]
    }
   ],
   "source": [
    "for key, val in response:\n",
    "    print(f\"{key}: {val}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
